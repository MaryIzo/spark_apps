{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f259d5-1a1c-4d33-9ee8-e71378f39b37",
   "metadata": {},
   "source": [
    "## Склеиватель файлов на hdfs\n",
    "FileGraphGluing - склеиватель файлов на hdfs можно применять к таблице (или списку таблиц) в личной директории или к директории с полным доступом, к одной партиции таблицы с подпартициями, к одной партиции с файлами.    \n",
    "Если известно, что в директории нет подпапок можно применить подфункцию: .gluing_for_file_path(string_path)   \n",
    "Вывести файлы в директории: get_list_files(path)  \n",
    "Вывести папки в директории: get_list_dir(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296500e-e8e7-4428-9148-286f86e45af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getpass\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4b7db-617c-4d76-af8a-e90b4f7a527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем объекты из модулей model_pipe\n",
    "from utils import build_spark, run_cmd\n",
    "from spark_gluer import FileGraphGluing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0596d34-f81c-4b03-9092-67d3bf60f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.utils as pysut\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb260bc-f1a8-4be6-b73b-d4f819cd2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2bd11-e179-4fe1-8e2e-e9c1484ebb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd7c62-00f1-4605-880c-d36501e995ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = 'python3.6' \n",
    "\n",
    "spark = build_spark(\n",
    "    app_name='spark_gluing', \n",
    "    user='username',\n",
    "    spark_home = '',\n",
    "    params = {\n",
    "        'spark.scheduler.mode': 'FIFO',\n",
    "        'spark.driver.memory': '20g', \n",
    "        'spark.driver.maxResultSize': '19g',\n",
    "        'spark.executor.memory': '30g',\n",
    "        'spark.executor.cores': '5',\n",
    "        'spark.dynamicAllocation.maxExecutors': '70',\n",
    "        'spark.sql.shuffle.partitions': '700',\n",
    "        'spark.yarn.executor.memoryOverhead': '5g'\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31f31d-c011-4f06-80ac-4d60589fea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223525c3-53c2-41a2-85bd-ab37dbcb8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.table(\"default.fs_test_joined_df\")\n",
    "sdf.repartition(1000).write.mode('overwrite').format('parquet').saveAsTable(\"default.fs_test_gluer_joined_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e3dad-8b93-4c36-a6b9-58fb92dd1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_path = \"hdfs://.../fs_test_gluer_joined_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df3bd5-2389-40a6-9f77-34f6c31db4d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = FileGraphGluing(spark, 128, 'parquet', True) # если таблица большая логи лучше указывать False, так как может зависнуть wrkon\n",
    "check.glue_directories_recursively(string_path, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c79f8-6a31-4532-96e3-d58f304c5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tables = \"\"\"HADOOP_USER_NAME=hdfs hdfs dfs -count /.../fs_test_gluer_joined_df | sort -k2 -nr | awk '{if ($2 > 0) print int($2) \"\\t\" int($3 / (1024*1024))\" Mb\\t\" ($3/(1024*1024*$2)) \"\\t\" $4}'\"\"\"\n",
    "out = run_cmd(default_tables, 'files check', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a25bc-a626-4664-ba24-f7890c9d4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('drop table if exists default.fs_test_gluer_joined_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6966c5-9503-4281-bd72-af8fa70894af",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.graph_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd0a80-6fca-4b47-9de5-d0fbb2f7689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8935a-cf07-4859-b347-5bb8abd8e986",
   "metadata": {},
   "source": [
    "### Команды hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38fd6e-71ca-467b-b97d-b178b4f0cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_dirs = \"\"\"\n",
    "HADOOP_USER_NAME=hdfs hdfs dfs -count /user/* | egrep -w -v \"yarn|hive|spark\" | sort -k2 -nr | \n",
    "awk '{ if ($2 > 1000) print int($2) \"\\t\\t\" int($3 / (1024*1024))\" Mb\\t\\t\" ($3/(1024*1024*$2)) \" Mb \\t \\t\" $4}'\n",
    "\"\"\"\n",
    "\n",
    "s_output_dirs, s_err = run_cmd(cmd_dirs, 'files check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ab2dd-f52b-4128-93a0-caf520a16b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_output_dirs = change_cmd_output(s_output_dirs, 'dirs')\n",
    "s_output_dirs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c74704-58df-4f20-bcd2-7d4b7b6494d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_name = \"\"\n",
    "mail_pass = getpass.getpass()\n",
    "\n",
    "send_email_old(mail_name, mail_pass, s_output_default, \"files in default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_pipe_venv",
   "language": "python",
   "name": "model_pipe_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
